{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Performance with MKL BLAS on MXNet 1.6 Deep Learning Containers\n",
    "\n",
    "Inference speed and performance is often times one of the most crucial factors for deciding to deploy a model in a production environment. Small increases in latency can be costly, so every bit of performance boost that can be had can help the overall costs. Because of our obessesion for customers, the MXNet team has brought a solution to improve the latency for inference using MXNet 1.6 Deep learning containers. In this post, we dicuss the improvement that was made to the MXNet 1.6.0 DLC version to make use of highly optimized matrix operators. The enhancement comes in the form of compiling MXNet with a dependency on Intel MKL BLAS instead of the default, oneDNN. As one will see, the performance boost can be up to 30% in latency reduction, making this a worthwhile option for our customers to implement in their production environment. To describe and show the enhancements in more detail, we will use the MNIST dataset to briefly give context of performing inference on Amazon SageMaker. Then, we will discuss the differences between the MKL BLAS and oneDNN libraries. Lastly, we will show how to implement the enhancement in your environment so that you can take advantage of the performance boost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: MXNet 1.7+ Deep Learning Containers have this enhancement as a default, so this solution applies to customers who don't want to change the MXNet version from 1.6.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker makes it really easy to deploy, host and maintain models. As part of that, choosing what framework or deep learning container to use is also a matter of setting a parameter. For the remainder of this post, we will use the MNIST dataset to quickly give examples for context and to show the performance difference between the MKL BLAS library and oneDNN library. But first, here is a brief example of how to perform inference in SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First we define a few variables that are needed to perform operations in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gluonnlp --quiet\n",
    "!pip install bert --quiet\n",
    "!pip install mxnet --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gluoncv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "import sagemaker\n",
    "from sagemaker.mxnet.model import MXNetModel, MXNetPredictor\n",
    "import pandas as pd\n",
    "from sagemaker import utils\n",
    "import boto3\n",
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import mxnet as mx\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import gluonnlp as nlp\n",
    "import cv2\n",
    "from transform import BERTDatasetTransform\n",
    "from gluonnlp.calibration import BertLayerCollector\n",
    "from utils import test_bert, deploy_bert, deploy_model\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = Session().default_bucket()\n",
    "\n",
    "# Bucket location where results of model training are saved.\n",
    "model_artifacts_location = 's3://{}/mxnet-mnist-example/artifacts'.format(bucket)\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()\n",
    "sagemaker_session = Session()\n",
    "region = boto3.Session().region_name\n",
    "test_data_location = 'sagemaker-sample-data-{}'.format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data \n",
    "\n",
    "This dataset contains 10,000 images that 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding=\"ISO-8859-1\", names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an inference Endpoint\n",
    "\n",
    "We use the ``MXNet model`` object to load model data and deploy an ``MXNetPredictor``. This creates a Sagemaker **Endpoint** -- a hosted prediction service that we can use to perform inference. \n",
    "\n",
    "The arguments to the ``deploy`` function allow us to set the number and type of instances that will be used for the Endpoint. Here we will deploy the model to a single ``ml.m4.xlarge`` instance. By not setting the ``image`` parameter, ``MXNetModel`` uses the default deep learning container image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MKL BLAS vs oneDNN\n",
    "\n",
    "The MKL BLAS and oneDNN libraries of math routines that are used to perform mathmatical operations on data. You can think of these as low level instructions that progamming languages use to perform computations. In the case of MXNet, it uses these libraries to for its operations such as dot products and other computationally expensive operations. MKL BLAS as version implemented by Intel, that uses highly optimized operators for CPU. These operators like the ``dot`` operator, are much faster than the operators found on the default library, oneDNN. So in order to take advantage of the speed boost, the MXNet team packaged the the MXNet 1.6 version with Intel's MKL BLAS library in a deep learning container available for use. In the diagram below, you can see the changes that are made between the different math libraries and MXNet versions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "In order to see the performance increase, we describe now how to implement the MKL BLAS and oneDNN based deep learning containers using SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oneDNN \n",
    "\n",
    "Notice the parameter ``image`` is set to a uri. This is the deep learning container uri, and the ``v3.7`` specifies a version of this MXNet 1.6 container that is compiled with oneDNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-----------------!\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.7\"\n",
    "onednn_predictor = deploy_bert(sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 55.409968686103824 Std: 0.12656422301418305 with 10 loops\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[55.78212642669678,\n",
       " 55.4226975440979,\n",
       " 55.36242318153381,\n",
       " 55.377811670303345,\n",
       " 55.33304786682129,\n",
       " 55.36034035682678,\n",
       " 55.37596607208252,\n",
       " 55.37017631530762,\n",
       " 55.3291597366333,\n",
       " 55.38593769073486]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = inference(tweets.text[:100], onednn_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MKL BLAS\n",
    "\n",
    "To specify the deep learning container with MKL BLAS, you change the version identifier in the image uri to ``v3.8``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-----------------!\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "mkl_predictor = deploy_bert(sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 48.03284316062927 Std: 0.09309706624115292 with 10 loops\n"
     ]
    }
   ],
   "source": [
    "times = inference(tweets.text[:100], mkl_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-------------------!\n",
      "Endpoint Name: bert-1605561706-78b3\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "mklq_predictor = deploy_bert(\"bert_sst_quantized.tar.gz\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"bert_inference_quantized.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 59.52104277610779 Std: 0.1776845656988009 with 10 loops\n"
     ]
    }
   ],
   "source": [
    "times = inference(tweets.text[:100], mklq_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint ssd-test-1606152661-97f8: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-75338192450e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mecr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-gpu-py36-cu101-ubuntu16.04-v3.7\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mssd_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeploy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ssd_512_resnet50_v1_voc.tar.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ssd-test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecr_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ml.c5.9xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1.6.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ssd_inference-batch50.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-389c9a2905eb>\u001b[0m in \u001b[0;36mdeploy_model\u001b[0;34m(model_data, endpoint_name, sagemaker_session, ecr_image, instance_type, framework_version, role, script, source_dir)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mendpoint_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name_from_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deploying...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEndpoint Name: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         )\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2709\u001b[0m         )\n\u001b[1;32m   2710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   2978\u001b[0m                 ),\n\u001b[1;32m   2979\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             )\n\u001b[1;32m   2982\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint ssd-test-1606152661-97f8: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-gpu-py36-cu101-ubuntu16.04-v3.7\"\n",
    "ssd_predictor = deploy_model(\"ssd_512_resnet50_v1_voc.tar.gz\", \"ssd-test\", sagemaker_session, ecr_image, 'ml.c5.9xlarge', \"1.6.0\", role, script=\"ssd_inference-batch50.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ssd_predictor = MXNetPredictor(\"ssd-test-1605820634-af4b\")\n",
    "img = cv2.imread(\"street_small.jpg\")\n",
    "times_ssd = inference(img, ssd_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "------------"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-gpu-py36-cu101-ubuntu16.04-v3.8\"\n",
    "mkl_ssd_predictor = deploy_model(\"ssd_512_resnet50_v1_voc.tar.gz\", \"ssd-test-mkl\", sagemaker_session, ecr_image, 'ml.p2.8xlarge', \"1.6.0\", role, script=\"ssd_inference.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_ssd_mkl = inference(img, mkl_ssd_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "---------------!\n",
      "Endpoint Name: ssd-neo-mkl-1605736102-329f\n"
     ]
    }
   ],
   "source": [
    "model_data = \"s3://sagemaker-us-east-1-254243159864/ssd-model/ssd_512_resnet50_v1_voc-ml_m4.tar.gz\"\n",
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "neo_mkl_ssd_predictor = deploy_model(model_data, \"ssd-neo-mkl\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"ssd_inference2.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_ssd_neo_mkl = inference(img, neo_mkl_ssd_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-------------!\n",
      "Endpoint Name: frcnn-test-1605737440-df00\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.7\"\n",
    "frcnn_predictor = deploy_model(\"faster_rcnn_resnet50_v1b_voc.tar.gz\", \"frcnn-test\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"faster_rcnn_inference.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 11.732010388374329 Std: 0.1700353891263145 with 10 loops\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"street_small.jpg\")\n",
    "times_ssd = inference(img, frcnn_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "--------------!\n",
      "Endpoint Name: frcnn--mkl-test-1605738209-c4bf\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "frcnn_mkl_predictor = deploy_model(\"faster_rcnn_resnet50_v1b_voc.tar.gz\", \"frcnn--mkl-test\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"faster_rcnn_inference.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 11.451266074180603 Std: 0.1609549418581635 with 10 loops\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"street_small.jpg\")\n",
    "times_fcrnn_mkl = inference(img, frcnn_mkl_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-----------------!\n",
      "Endpoint Name: frcnn--mkl-test-1605738953-bb57\n"
     ]
    }
   ],
   "source": [
    "frcnn_17_predictor = deploy_model(\"faster_rcnn_resnet50_v1b_voc.tar.gz\", \"frcnn--mkl-test\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.7.0\", role, script=\"faster_rcnn_inference.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 11.490782737731934 Std: 0.14977126993494028 with 10 loops\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"street_small.jpg\")\n",
    "frcnn_17_predictor = MXNetPredictor(\"frcnn--mkl-test-1605738953-bb57\")\n",
    "times_fcrnn_17 = inference(img, frcnn_17_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "---------------!\n",
      "Endpoint Name: frcnn-test-1605740117-a6cf\n",
      "Deploying...\n",
      "-----------------!\n",
      "Endpoint Name: frcnn--mkl-test-1605740582-9555\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.7\"\n",
    "frcnn_predictor50 = deploy_model(\"faster_rcnn_resnet50_v1b_voc.tar.gz\", \"frcnn-test\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"faster_rcnn_inference_batch50.py\")\n",
    "\n",
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "frcnn_mkl_predictor50 = deploy_model(\"faster_rcnn_resnet50_v1b_voc.tar.gz\", \"frcnn--mkl-test\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"faster_rcnn_inference_batch50.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"Error in operator fasterrcnn0_concat0: [23:12:06] src/operator/nn/concat.cc:67: Check failed: shape_assign(&(*in_shape)[i], dshape): Incompatible input shape: expected [300,-1], got [15000,4]\nStack trace:\n  [bt] (0) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32952b) [0x7ff2beeed52b]\n  [bt] (1) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9edc0b) [0x7ff2bf5b1c0b]\n  [bt] (2) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x35704fc) [0x7ff2c21344fc]\n  [bt] (3) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3573d88) [0x7ff2c2137d88]\n  [bt] (4) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x358d9cf) [0x7ff2c21519cf]\n  [bt] (5) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::CheckDynamicShapeExists(mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool)+0x3f3) [0x7ff2c2163cb3]\n  [bt] (6) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::Forward(std::shared_ptr<mxnet::CachedOp> const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0xaac) [0x7ff2c2167a7c]\n  [bt] (7) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOp+0x3f0) [0x7ff2c20675d0]\n  [bt] (8) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOpEx+0x40) [0x7ff2c2068640]\n\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 126, in transform\n    result = self._transform_fn(self._model, input_data, content_type, accept)\n  File \"/opt/ml/model/code/faster_rcnn_inference_batch50.py\", line 76, in transform_fn\n    cid, score, bbox = net(batch)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 758, in __call__\n    out = self.forward(*args)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1393, in forward\n    return self._call_cached_op(x, *args)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1085, in _call_cached_op\n    out = self._cached_op(*cargs)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\", line 170, in __call__\n    ctypes.byref(out_stypes)))\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 255, in check_call\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\nmxnet.base.MXNetError: Error in operator fasterrcnn0_concat0: [23:12:06] src/operator/nn/concat.cc:67: Check failed: shape_assign(&(*in_shape)[i], dshape): Incompatible input shape: expected [300,-1], got [15000,4]\nStack trace:\n  [bt] (0) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32952b) [0x7ff2beeed52b]\n  [bt] (1) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9edc0b) [0x7ff2bf5b1c0b]\n  [bt] (2) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x35704fc) [0x7ff2c21344fc]\n  [bt] (3) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3573d88) [0x7ff2c2137d88]\n  [bt] (4) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x358d9cf) [0x7ff2c21519cf]\n  [bt] (5) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::CheckDynamicShapeExists(mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool)+0x3f3) [0x7ff2c2163cb3]\n  [bt] (6) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::Forward(std::shared_ptr<mxnet::CachedOp> const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0xaac) [0x7ff2c2167a7c]\n  [bt] (7) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOp+0x3f0) [0x7ff2c20675d0]\n  [bt] (8) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOpEx+0x40) [0x7ff2c2068640]\n\n\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/frcnn-test-1605740117-a6cf in account 254243159864 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-28babe8fa6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"street_small.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtimes_ssd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrcnn_predictor50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtimes_fcrnn_mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrcnn_mkl_predictor50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-6ab01950ae3b>\u001b[0m in \u001b[0;36minference\u001b[0;34m(data, predictor, loops)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"Error in operator fasterrcnn0_concat0: [23:12:06] src/operator/nn/concat.cc:67: Check failed: shape_assign(&(*in_shape)[i], dshape): Incompatible input shape: expected [300,-1], got [15000,4]\nStack trace:\n  [bt] (0) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32952b) [0x7ff2beeed52b]\n  [bt] (1) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9edc0b) [0x7ff2bf5b1c0b]\n  [bt] (2) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x35704fc) [0x7ff2c21344fc]\n  [bt] (3) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3573d88) [0x7ff2c2137d88]\n  [bt] (4) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x358d9cf) [0x7ff2c21519cf]\n  [bt] (5) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::CheckDynamicShapeExists(mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool)+0x3f3) [0x7ff2c2163cb3]\n  [bt] (6) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::Forward(std::shared_ptr<mxnet::CachedOp> const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0xaac) [0x7ff2c2167a7c]\n  [bt] (7) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOp+0x3f0) [0x7ff2c20675d0]\n  [bt] (8) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOpEx+0x40) [0x7ff2c2068640]\n\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/sagemaker_inference/transformer.py\", line 126, in transform\n    result = self._transform_fn(self._model, input_data, content_type, accept)\n  File \"/opt/ml/model/code/faster_rcnn_inference_batch50.py\", line 76, in transform_fn\n    cid, score, bbox = net(batch)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 758, in __call__\n    out = self.forward(*args)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1393, in forward\n    return self._call_cached_op(x, *args)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/gluon/block.py\", line 1085, in _call_cached_op\n    out = self._cached_op(*cargs)\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\", line 170, in __call__\n    ctypes.byref(out_stypes)))\n  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 255, in check_call\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\nmxnet.base.MXNetError: Error in operator fasterrcnn0_concat0: [23:12:06] src/operator/nn/concat.cc:67: Check failed: shape_assign(&(*in_shape)[i], dshape): Incompatible input shape: expected [300,-1], got [15000,4]\nStack trace:\n  [bt] (0) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x32952b) [0x7ff2beeed52b]\n  [bt] (1) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9edc0b) [0x7ff2bf5b1c0b]\n  [bt] (2) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x35704fc) [0x7ff2c21344fc]\n  [bt] (3) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3573d88) [0x7ff2c2137d88]\n  [bt] (4) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x358d9cf) [0x7ff2c21519cf]\n  [bt] (5) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::CheckDynamicShapeExists(mxnet::Context const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, bool)+0x3f3) [0x7ff2c2163cb3]\n  [bt] (6) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::CachedOp::Forward(std::shared_ptr<mxnet::CachedOp> const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0xaac) [0x7ff2c2167a7c]\n  [bt] (7) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOp+0x3f0) [0x7ff2c20675d0]\n  [bt] (8) /usr/local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXInvokeCachedOpEx+0x40) [0x7ff2c2068640]\n\n\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/frcnn-test-1605740117-a6cf in account 254243159864 for more information."
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"street_small.jpg\")\n",
    "times_ssd = inference(img, frcnn_predictor50)\n",
    "times_fcrnn_mkl = inference(img, frcnn_mkl_predictor50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Delete the Endpoint\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()\n",
    "oneDNN_predictor.delete_endpoint()\n",
    "mklblas_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-------------------!\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.7\"\n",
    "onednn_predictor = test_bert(sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(10):\n",
    "    output = onednn_predictor.predict(list(tweets.text[:100]))\n",
    "    times.append(output['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 55.713221716880795\n",
      "Std: 0.20049065918782286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Avg:\", np.mean(times))\n",
    "print(\"Std:\", np.std(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "---------------!\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "mkl_predictor = test_bert(sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(10):\n",
    "    output = mkl_predictor.predict(list(tweets.text[:100]))\n",
    "    times.append(output[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg: 48.21942739486694\n",
      "Std: 0.34405162161675223\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg:\", np.mean(times))\n",
    "print(\"Std:\", np.std(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying...\n",
      "-----------------!\n",
      "Endpoint Name: bert-1605559584-3701\n"
     ]
    }
   ],
   "source": [
    "ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py36-ubuntu16.04-v3.8\"\n",
    "mklq_predictor = deploy_bert(\"bert_sst_quantized.tar.gz\", sagemaker_session, ecr_image, 'ml.m4.xlarge', \"1.6.0\", role, script=\"bert_inference_quantized.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(10):\n",
    "    output = mklq_predictor.predict(list(tweets.text[:100]))\n",
    "    times.append(output['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avg:\", np.mean(times))\n",
    "print(\"Std:\", np.std(times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
